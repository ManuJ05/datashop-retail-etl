# DataShop Retail Data Warehouse & ETL Pipeline

![Data Warehouse Star Schema Diagram]

## üéØ Objetivo del Proyecto
[cite_start]Este proyecto desarrolla una **soluci√≥n integral de Business Intelligence (BI)** para la empresa ficticia DataShop[cite: 13]. [cite_start]El objetivo principal es modelar, transformar y almacenar datos de ventas para permitir an√°lisis informados y la toma de decisiones[cite: 7].

---

## üèóÔ∏è Arquitectura y Modelado (Esquema Estrella)

La soluci√≥n implementa una arquitectura de Data Warehouse (DW) con un **Esquema Estrella** en SQL Server.

### Componentes Clave
| Tipo | Tabla | Claves √önicas | Atributos Clave |
| :--- | :--- | :--- | :--- |
| **Hechos** | `dw.Fact_Ventas` | FechaClave, SurrogateKeys | Cantidad, PrecioVenta, **ImporteTotal (Calculado)** |
| **Dimensi√≥n** | `dw.Dim_Cliente` | SurrogateKey_Cliente, CodCliente | RazonSocial, Mail, Direcci√≥n |
| **Dimensi√≥n** | `dw.Dim_Producto` | SurrogateKey_Producto, CodigoProducto | Descripci√≥n, Categor√≠a, Marca |
| **Dimensi√≥n** | `dw.Dim_Tienda` | SurrogateKey_Tienda, CodigoTienda | Localidad, Provincia, TipoTienda |
| **Dimensi√≥n** | `dw.Dim_Tiempo` | Tiempo_Key (YYYYMMDD) | A√±o, Mes, Trimestre |

### Flujo ETL
El proceso de carga se divide en dos fases orquestadas por Python:

1.  **Extracci√≥n/Carga (EL):** Scripts de Python leen archivos `.csv` (origen) y cargan los datos crudos en tablas de **Staging** (`stg`).
2.  **Transformaci√≥n y Carga Final (T/L):** Un procedimiento almacenado de SQL aplica la l√≥gica de negocio (`MERGE`), genera las claves subrogadas (`Surrogate Keys`), y mueve los datos limpios a las tablas finales del DW (`dw`).

## üõ†Ô∏è Tecnolog√≠as
* **Base de Datos:** SQL Server (Gesti√≥n de DW y Stored Procedures).
* **Lenguaje:** Python 3.x
* **Librer√≠as Python:** `pandas` (Extracci√≥n de CSVs), `sqlalchemy` y `pyodbc` (Conexi√≥n a SQL).
* **Visualizaci√≥n:** Power BI (Reportes anal√≠ticos avanzados).

---

## üöÄ C√≥mo Ejecutar el Proyecto (Configuraci√≥n)

### Requisitos
1.  Instancia de SQL Server (ej: `.\SQLEXPRESS`).
2.  Driver ODBC 17 for SQL Server instalado.
3.  Python y dependencias (`pip install pandas sqlalchemy pyodbc`).

### Pasos de Ejecuci√≥n
1.  **Configurar la Base de Datos:** Ejecute el script **`script_creacion_dw.sql`** en SQL Server Management Studio (SSMS). Este script crea las tablas, los esquemas y los procedimientos almacenados (incluyendo la l√≥gica de `Dim_Tiempo`).
2.  **Carga de Datos Inicial (Stage):** Ejecute el script de extracci√≥n.
    ```bash
    python cargar_csv_a_stage.py
    ```
3.  **Ejecuci√≥n del ETL Completo (T/L):** Ejecute el script orquestador para llenar las Dimensiones y Hechos, y ejecutar las transformaciones.
    ```bash
    python ejecutar_etl_completo.py
    ```

## üìä Resultado Final: Dashboard Power BI

[cite_start]El tablero final contiene un an√°lisis completo de las ventas, cumpliendo con los siguientes requisitos[cite: 91, 92, 94]:

* [cite_start]**KPIs:** Importe Total de Ventas [cite: 93][cite_start], Cantidad de Ventas realizadas[cite: 94], Precio Promedio.
* [cite_start]**An√°lisis Temporal:** Gr√°fico de Barras que muestra las Ventas por A√±o y por Mes[cite: 96, 97].
* [cite_start]**An√°lisis Comparativo (Avanzado):** Matriz que utiliza medidas DAX y formato condicional (sem√°foro) para mostrar el % de Variaci√≥n de Ventas mes a mes[cite: 137, 140].
